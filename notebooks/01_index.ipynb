{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49fc2e18",
   "metadata": {},
   "source": [
    "### 1) Load PDFs and split , indexing to chunks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e5ed95",
   "metadata": {},
   "source": [
    "import library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db1c760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9ee0d0",
   "metadata": {},
   "source": [
    "PDFs' path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69c2e1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: ../data/Automotive_SPICE_PAM_31_EN.pdf\n",
      "File exists: ../data/AUTOSAR_SWS_ECUStateManager.pdf\n"
     ]
    }
   ],
   "source": [
    "pdf_paths = [\n",
    "    \"../data/Automotive_SPICE_PAM_31_EN.pdf\",\n",
    "    \"../data/AUTOSAR_SWS_ECUStateManager.pdf\"\n",
    "]\n",
    "\n",
    "# Verify files exist before loading\n",
    "for path in pdf_paths:\n",
    "    if not Path(path).exists():\n",
    "        print(f\"Warning: File not found - {path}\")\n",
    "    else:\n",
    "        print(f\"File exists: {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97967a3c",
   "metadata": {},
   "source": [
    "Load PDFs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2da1e537",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for path in pdf_paths:\n",
    "  loader = PyPDFLoader(path)\n",
    "  docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1c30f5",
   "metadata": {},
   "source": [
    "split PDFs to Chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "953b6b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "  chunk_size = 500, chunk_overlap  = 50, \n",
    "  separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "chunks = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8566329",
   "metadata": {},
   "source": [
    "Add IDS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea04c629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1492"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, chunk in enumerate(chunks):\n",
    "  chunk.metadata[\"chunk_id\"] = i\n",
    "  if \"source\" in chunk.metadata:\n",
    "    chunk.metadata[\"doc_id\"] = Path(chunk.metadata[\"source\"]).stem\n",
    "  else:\n",
    "    chunk.metadata[\"doc_id\"] = \"unknown\"\n",
    "\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eed153",
   "metadata": {},
   "source": [
    "### 2) Build indexing Dense (Faiss + Gemini Embeddings )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c16be54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AqaInput', 'AqaOutput', 'ChatGoogleGenerativeAI', 'DoesNotExistsException', 'GenAIAqa', 'GoogleGenerativeAI', 'GoogleGenerativeAIEmbeddings', 'GoogleVectorStore', 'HarmBlockThreshold', 'HarmCategory', 'Modality', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_common', '_enums', '_function_utils', '_genai_extension', '_image_utils', 'chat_models', 'embeddings', 'genai_aqa', 'google_vector_store', 'llms']\n"
     ]
    }
   ],
   "source": [
    "import langchain_google_genai\n",
    "print(dir(langchain_google_genai))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21beac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import os \n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21fec227",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c219b87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/gemini-embedding-001\",\n",
    "    google_api_key=GEMINI_API_KEY\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42aa38ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM = ChatGoogleGenerativeAI(\n",
    "  api_key = GEMINI_API_KEY, \n",
    "  model=\"gemini-2.5-pro\",\n",
    "  temperature=0.2,\n",
    "  max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab4ad38",
   "metadata": {},
   "source": [
    "### 3) BM25 (rank_bm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "469ce6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, pickle\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0105ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokeize(text:str):\n",
    "  return re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "\n",
    "corpus_tokens = [tokeize(chunk.page_content) for chunk in chunks]\n",
    "bm25 = BM25Okapi(corpus_tokens)\n",
    "\n",
    "with open(\"../artifacts/bm25_corpus.pkl\", \"wb\") as f:\n",
    "  pickle.dump({\"corpus_tokens\":corpus_tokens}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d7cb5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os \n",
    "with open(\"../artifacts/chunks.jsonl\", \"w\", encoding =\"utf-8\") as f:\n",
    "  for chunk in chunks:\n",
    "    f.write(json.dumps({\n",
    "      \"chunk_id\": chunk.metadata[\"chunk_id\"],\n",
    "      \"doc_id\": chunk.metadata[\"doc_id\"],\n",
    "      \"page\" : chunk.metadata.get(\"page\", None),\n",
    "      \"text\" : chunk.page_content\n",
    "    }, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b159ced5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
